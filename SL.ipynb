{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8dsmCyODtSS"
   },
   "source": [
    "# **Goal: Recommendation System / Next Best Action**\n",
    "\n",
    "## **Context**\n",
    "We have a **random extraction** of a (real world) dataset containing **customers of a large wealth management company**.  \n",
    "\n",
    "The data is **anonymous, mostly clean, and NOT always normalized/scaled**.  \n",
    "\n",
    "Our objective is to **estimate investment needs** for these customers using **Data Science techniques**.\n",
    "\n",
    "### **Why Estimate Investment Needs?**\n",
    "Identifying customer needs is useful for several reasons, including:\n",
    "\n",
    "* **Recommender Systems / Next Best Action:**  \n",
    "  * Needs can serve as **key inputs** for **content-based** or **knowledge-based filtering algorithms**, that allows for personalized services.  \n",
    "  * This is our **primary focus** in this notebook, i.e., \"Know Your Client (KYC)\".  \n",
    "\n",
    "* **Product Targeting & Governance (Regulatory Compliance - MIFID/IDD in EU):**  \n",
    "  * Regulatory standards require that **customer needs match the investment products offered**. So financial institutions must estimate customer needs.\n",
    "  * This is essentially an **\"institutional view\"** of a recommendation system...\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## **Dataset Overview**\n",
    "The dataset, named **\"Needs\"**, is stored in an **Excel file called Dataset2_Needs.xls**.  \n",
    "It contains several **potentially relevant features** along with two **target variables**, i.e:\n",
    "\n",
    "* **AccumulationInvestment**  \n",
    "  * Indicates a customer preference for **accumulation investing**, typically through **dollar-cost averaging** (i.e., investing small amounts at regular intervals over time, say on a monthly basis).  \n",
    "  * **Binary (Boolean) response:**  \n",
    "    * `1 = High propensity`.  \n",
    "    * `0 = Low propensity`.\n",
    "\n",
    "- **IncomeInvestment**  \n",
    "  - Indicates a customer preference for **income investing**, typically through **lump-sum investing** (i.e., one-shot investments).  This is because anyone who aspires to obtain income from coupons and dividends must necessarily already have accumulated capital - a typical need of people who are older than their previous need.\n",
    "  - **Binary (Boolean) response:**  \n",
    "    - `1 = High propensity`.  \n",
    "    - `0 = Low propensity`.  \n",
    "\n",
    "    **Where do these two response variables come from?** From a **revealed preference scheme**: if the client has an advisor who is considered professionally reliable (this eliminates the possibility of conflict of interest) and has purchased a product that satisfies that need, and the client has also purchased it, we can say with good probability that the advisor has identified the need correctly and the client has that need. In other respects, the machine learning model we are building is a clone of the financial advisor.\n",
    "\n",
    "<br>\n",
    "\n",
    "Additionally, we have a **second dataset**, **\"Products\"**, containing investment products (funds, segregated accounts, unit-linked policies), along with:\n",
    "\n",
    "* **Product Type:**  \n",
    "  * `1 = Accumulation` (that is, a product that is good for those who have a high need for accumulation investments)\n",
    "  * `0 = Income`  (that is, a product that is good for those who have a high need for income investments)\n",
    "\n",
    "* **Risk Level:**  \n",
    "  * A **normalized risk score** in the range **$[0,1]$**.  \n",
    "  * This usually represents the normalized value in $[0, 1]$ of the **[Synthetic Risk and Reward Indicator (SRRI)](https://www.esma.europa.eu/sites/default/files/library/2015/11/10_673.pdf)** of the product, an ordinal variable defined in the range ${1, 7}$ starting from continuous data.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## **Recommendation System Approach**\n",
    "The recommendation system consists of **two key steps**:\n",
    "\n",
    "1. **Identifying customers with high investment propensity:**  \n",
    "   - Using **machine learning models**, we aim to classify customers based on **AccumulationInvestment** (`1 = High propensity`) and/or **IncomeInvestment** (`1 = High propensity`).  \n",
    "\n",
    "2. **Recommending the most suitable product for each customer:**  \n",
    "   - For each customer, we match the **most appropriate product** based on:  \n",
    "     - **Investment need** (Accumulation or Income).  \n",
    "     - **Risk compatibility** (matching product risk level with the customer profile).  \n",
    "   - This **personalized recommendation** represents the **Next Best Action** for each client.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OQ69Ayshtix"
   },
   "source": [
    "<br>\n",
    "\n",
    "Let's start with data ingestion.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26637,
     "status": "ok",
     "timestamp": 1744208306706,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "yl7i0FggD4WS",
    "outputId": "b216dad5-f651-4414-98ed-6ce8c4701a09"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.vscode', 'BaseNotebook.ipynb', 'dataset', 'Dataset2_Needs.xlsx', 'FeaEngwithDecisionTree.ipynb', 'Projectwork_Zenti.pdf', 'RIJ.ipynb', 'SL.ipynb', 'Zenti_Business_Case_2.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = r'C:\\Users\\leo_h\\Documents\\project\\fintech_final_project'\n",
    "print(os.listdir(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2608,
     "status": "ok",
     "timestamp": 1744208310387,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "yw-38OF-ER6E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\leo_h\\Documents\\project\\fintech_final_project\n",
      "Looking for file at: Dataset2_Needs.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = r'C:\\Users\\leo_h\\Documents\\project\\fintech_final_project'\n",
    "file_path = \"Dataset2_Needs.xlsx\"\n",
    "\n",
    "os.chdir(folder)\n",
    "os.getcwd()\n",
    "# Print current working directory for debugging\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Looking for file at:\", file_path)\n",
    "\n",
    "# 'folder' and 'file_path' are already defined in the notebook, so we use them directly\n",
    "\n",
    "\n",
    "\n",
    "needs_df = pd.read_excel(file_path, sheet_name='Needs')\n",
    "products_df = pd.read_excel(file_path, sheet_name='Products')\n",
    "metadata_df = pd.read_excel(file_path, sheet_name='Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8rBxNZm1y1c"
   },
   "source": [
    "# **Data Exploration**\n",
    "\n",
    "As for the last business case: I keep it minimalist, for the benefit of brevity, to be able to get to the heart of the problem. But you could/can spend tons of time here in order to **understand the problem and the dataset**.\n",
    "\n",
    "Let's display our variables to better understand the data structure and characteristics of the dataset.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1743959855093,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "KWfnnvYhDr0I",
    "outputId": "13a55284-d72a-47d1-b731-8d107a821fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata DataFrame columns:\n",
      "['Metadata', 'Unnamed: 1']\n",
      "\n",
      "First few rows of metadata:\n",
      "        Metadata                     Unnamed: 1\n",
      "0        Clients                            NaN\n",
      "1             ID                   Numerical ID\n",
      "2            Age                  Age, in years\n",
      "3         Gender  Gender (Female = 1, Male = 0)\n",
      "4  FamilyMembers           Number of components\n"
     ]
    }
   ],
   "source": [
    "# Let's see the actual variables names in metadata_df\n",
    "print(\"Metadata DataFrame columns:\")\n",
    "print(metadata_df.columns.tolist())\n",
    "\n",
    "# Let's peek at the first few rows\n",
    "print(\"\\nFirst few rows of metadata:\")\n",
    "print(metadata_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sup4ADyjwJz"
   },
   "source": [
    "<br>\n",
    "\n",
    "We drop ID column as it's not needed for analysis.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1744208314502,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "V0jbZ011jxpM"
   },
   "outputs": [],
   "source": [
    "# Drop ID column as it's not needed for analysis\n",
    "needs_df = needs_df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDj4h3OkNHKe"
   },
   "source": [
    "<br>\n",
    "\n",
    "Create a formatted table to summarize the dataset (you can expand the number of statistics you look at).\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1744208317966,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "_R5UqaEu8kc6",
    "outputId": "c5e4aaf8-fd8a-4da7-cbd7-4d008874d924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEEDS VARIABLES SUMMARY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b9e6e_row0_col0, #T_b9e6e_row0_col1, #T_b9e6e_row0_col2, #T_b9e6e_row0_col3, #T_b9e6e_row0_col4, #T_b9e6e_row0_col5, #T_b9e6e_row0_col6, #T_b9e6e_row1_col0, #T_b9e6e_row1_col1, #T_b9e6e_row1_col2, #T_b9e6e_row1_col3, #T_b9e6e_row1_col4, #T_b9e6e_row1_col5, #T_b9e6e_row1_col6, #T_b9e6e_row2_col0, #T_b9e6e_row2_col1, #T_b9e6e_row2_col2, #T_b9e6e_row2_col3, #T_b9e6e_row2_col4, #T_b9e6e_row2_col5, #T_b9e6e_row2_col6, #T_b9e6e_row3_col0, #T_b9e6e_row3_col1, #T_b9e6e_row3_col2, #T_b9e6e_row3_col3, #T_b9e6e_row3_col4, #T_b9e6e_row3_col5, #T_b9e6e_row3_col6, #T_b9e6e_row4_col0, #T_b9e6e_row4_col1, #T_b9e6e_row4_col2, #T_b9e6e_row4_col3, #T_b9e6e_row4_col4, #T_b9e6e_row4_col5, #T_b9e6e_row4_col6, #T_b9e6e_row5_col0, #T_b9e6e_row5_col1, #T_b9e6e_row5_col2, #T_b9e6e_row5_col3, #T_b9e6e_row5_col4, #T_b9e6e_row5_col5, #T_b9e6e_row5_col6, #T_b9e6e_row6_col0, #T_b9e6e_row6_col1, #T_b9e6e_row6_col2, #T_b9e6e_row6_col3, #T_b9e6e_row6_col4, #T_b9e6e_row6_col5, #T_b9e6e_row6_col6, #T_b9e6e_row7_col0, #T_b9e6e_row7_col1, #T_b9e6e_row7_col2, #T_b9e6e_row7_col3, #T_b9e6e_row7_col4, #T_b9e6e_row7_col5, #T_b9e6e_row7_col6, #T_b9e6e_row8_col0, #T_b9e6e_row8_col1, #T_b9e6e_row8_col2, #T_b9e6e_row8_col3, #T_b9e6e_row8_col4, #T_b9e6e_row8_col5, #T_b9e6e_row8_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b9e6e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b9e6e_level0_col0\" class=\"col_heading level0 col0\" >Variable</th>\n",
       "      <th id=\"T_b9e6e_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th id=\"T_b9e6e_level0_col2\" class=\"col_heading level0 col2\" >Mean</th>\n",
       "      <th id=\"T_b9e6e_level0_col3\" class=\"col_heading level0 col3\" >Std</th>\n",
       "      <th id=\"T_b9e6e_level0_col4\" class=\"col_heading level0 col4\" >Missing</th>\n",
       "      <th id=\"T_b9e6e_level0_col5\" class=\"col_heading level0 col5\" >Min</th>\n",
       "      <th id=\"T_b9e6e_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row0_col0\" class=\"data row0 col0\" >Age</td>\n",
       "      <td id=\"T_b9e6e_row0_col1\" class=\"data row0 col1\" >Age, in years</td>\n",
       "      <td id=\"T_b9e6e_row0_col2\" class=\"data row0 col2\" >55.25</td>\n",
       "      <td id=\"T_b9e6e_row0_col3\" class=\"data row0 col3\" >11.97</td>\n",
       "      <td id=\"T_b9e6e_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row0_col5\" class=\"data row0 col5\" >18.00</td>\n",
       "      <td id=\"T_b9e6e_row0_col6\" class=\"data row0 col6\" >97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row1_col0\" class=\"data row1 col0\" >Gender</td>\n",
       "      <td id=\"T_b9e6e_row1_col1\" class=\"data row1 col1\" >Gender (Female = 1, Male = 0)</td>\n",
       "      <td id=\"T_b9e6e_row1_col2\" class=\"data row1 col2\" >0.49</td>\n",
       "      <td id=\"T_b9e6e_row1_col3\" class=\"data row1 col3\" >0.50</td>\n",
       "      <td id=\"T_b9e6e_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_b9e6e_row1_col6\" class=\"data row1 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row2_col0\" class=\"data row2 col0\" >FamilyMembers</td>\n",
       "      <td id=\"T_b9e6e_row2_col1\" class=\"data row2 col1\" >Number of components</td>\n",
       "      <td id=\"T_b9e6e_row2_col2\" class=\"data row2 col2\" >2.51</td>\n",
       "      <td id=\"T_b9e6e_row2_col3\" class=\"data row2 col3\" >0.76</td>\n",
       "      <td id=\"T_b9e6e_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row2_col5\" class=\"data row2 col5\" >1.00</td>\n",
       "      <td id=\"T_b9e6e_row2_col6\" class=\"data row2 col6\" >5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row3_col0\" class=\"data row3 col0\" >FinancialEducation</td>\n",
       "      <td id=\"T_b9e6e_row3_col1\" class=\"data row3 col1\" >Normalized level of Financial Education (estimate)</td>\n",
       "      <td id=\"T_b9e6e_row3_col2\" class=\"data row3 col2\" >0.42</td>\n",
       "      <td id=\"T_b9e6e_row3_col3\" class=\"data row3 col3\" >0.15</td>\n",
       "      <td id=\"T_b9e6e_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row3_col5\" class=\"data row3 col5\" >0.04</td>\n",
       "      <td id=\"T_b9e6e_row3_col6\" class=\"data row3 col6\" >0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row4_col0\" class=\"data row4 col0\" >RiskPropensity</td>\n",
       "      <td id=\"T_b9e6e_row4_col1\" class=\"data row4 col1\" >Normalized Risk propensity from MIFID profile</td>\n",
       "      <td id=\"T_b9e6e_row4_col2\" class=\"data row4 col2\" >0.36</td>\n",
       "      <td id=\"T_b9e6e_row4_col3\" class=\"data row4 col3\" >0.15</td>\n",
       "      <td id=\"T_b9e6e_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row4_col5\" class=\"data row4 col5\" >0.02</td>\n",
       "      <td id=\"T_b9e6e_row4_col6\" class=\"data row4 col6\" >0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row5_col0\" class=\"data row5 col0\" >Income </td>\n",
       "      <td id=\"T_b9e6e_row5_col1\" class=\"data row5 col1\" >Income (thousands of euros); estimate</td>\n",
       "      <td id=\"T_b9e6e_row5_col2\" class=\"data row5 col2\" >62.99</td>\n",
       "      <td id=\"T_b9e6e_row5_col3\" class=\"data row5 col3\" >44.36</td>\n",
       "      <td id=\"T_b9e6e_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row5_col5\" class=\"data row5 col5\" >1.54</td>\n",
       "      <td id=\"T_b9e6e_row5_col6\" class=\"data row5 col6\" >365.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row6_col0\" class=\"data row6 col0\" >Wealth</td>\n",
       "      <td id=\"T_b9e6e_row6_col1\" class=\"data row6 col1\" >Wealth (thousands of euros); sum of investments and cash accounts</td>\n",
       "      <td id=\"T_b9e6e_row6_col2\" class=\"data row6 col2\" >93.81</td>\n",
       "      <td id=\"T_b9e6e_row6_col3\" class=\"data row6 col3\" >105.47</td>\n",
       "      <td id=\"T_b9e6e_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row6_col5\" class=\"data row6 col5\" >1.06</td>\n",
       "      <td id=\"T_b9e6e_row6_col6\" class=\"data row6 col6\" >2233.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row7_col0\" class=\"data row7 col0\" >IncomeInvestment</td>\n",
       "      <td id=\"T_b9e6e_row7_col1\" class=\"data row7 col1\" >Boolean variable for Income investment; 1 = High propensity</td>\n",
       "      <td id=\"T_b9e6e_row7_col2\" class=\"data row7 col2\" >0.38</td>\n",
       "      <td id=\"T_b9e6e_row7_col3\" class=\"data row7 col3\" >0.49</td>\n",
       "      <td id=\"T_b9e6e_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row7_col5\" class=\"data row7 col5\" >0.00</td>\n",
       "      <td id=\"T_b9e6e_row7_col6\" class=\"data row7 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9e6e_row8_col0\" class=\"data row8 col0\" >AccumulationInvestment</td>\n",
       "      <td id=\"T_b9e6e_row8_col1\" class=\"data row8 col1\" >Boolean variable for Accumulation/growth investment; 1 = High propensity</td>\n",
       "      <td id=\"T_b9e6e_row8_col2\" class=\"data row8 col2\" >0.51</td>\n",
       "      <td id=\"T_b9e6e_row8_col3\" class=\"data row8 col3\" >0.50</td>\n",
       "      <td id=\"T_b9e6e_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_b9e6e_row8_col5\" class=\"data row8 col5\" >0.00</td>\n",
       "      <td id=\"T_b9e6e_row8_col6\" class=\"data row8 col6\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d1cced3cb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRODUCTS VARIABLES SUMMARY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5a406_row0_col0, #T_5a406_row0_col1, #T_5a406_row0_col2, #T_5a406_row0_col3, #T_5a406_row0_col4, #T_5a406_row0_col5, #T_5a406_row0_col6, #T_5a406_row1_col0, #T_5a406_row1_col1, #T_5a406_row1_col2, #T_5a406_row1_col3, #T_5a406_row1_col4, #T_5a406_row1_col5, #T_5a406_row1_col6, #T_5a406_row2_col0, #T_5a406_row2_col1, #T_5a406_row2_col2, #T_5a406_row2_col3, #T_5a406_row2_col4, #T_5a406_row2_col5, #T_5a406_row2_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5a406\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5a406_level0_col0\" class=\"col_heading level0 col0\" >Variable</th>\n",
       "      <th id=\"T_5a406_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th id=\"T_5a406_level0_col2\" class=\"col_heading level0 col2\" >Mean</th>\n",
       "      <th id=\"T_5a406_level0_col3\" class=\"col_heading level0 col3\" >Std</th>\n",
       "      <th id=\"T_5a406_level0_col4\" class=\"col_heading level0 col4\" >Missing</th>\n",
       "      <th id=\"T_5a406_level0_col5\" class=\"col_heading level0 col5\" >Min</th>\n",
       "      <th id=\"T_5a406_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5a406_row0_col0\" class=\"data row0 col0\" >IDProduct</td>\n",
       "      <td id=\"T_5a406_row0_col1\" class=\"data row0 col1\" >Product description</td>\n",
       "      <td id=\"T_5a406_row0_col2\" class=\"data row0 col2\" >6.00</td>\n",
       "      <td id=\"T_5a406_row0_col3\" class=\"data row0 col3\" >3.32</td>\n",
       "      <td id=\"T_5a406_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_5a406_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_5a406_row0_col6\" class=\"data row0 col6\" >11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5a406_row1_col0\" class=\"data row1 col0\" >Type</td>\n",
       "      <td id=\"T_5a406_row1_col1\" class=\"data row1 col1\" >1 = Accumulation product, 0 = Income product </td>\n",
       "      <td id=\"T_5a406_row1_col2\" class=\"data row1 col2\" >0.64</td>\n",
       "      <td id=\"T_5a406_row1_col3\" class=\"data row1 col3\" >0.50</td>\n",
       "      <td id=\"T_5a406_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_5a406_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_5a406_row1_col6\" class=\"data row1 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5a406_row2_col0\" class=\"data row2 col0\" >Risk</td>\n",
       "      <td id=\"T_5a406_row2_col1\" class=\"data row2 col1\" >Normalized Synthetic Risk Indicator</td>\n",
       "      <td id=\"T_5a406_row2_col2\" class=\"data row2 col2\" >0.43</td>\n",
       "      <td id=\"T_5a406_row2_col3\" class=\"data row2 col3\" >0.24</td>\n",
       "      <td id=\"T_5a406_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_5a406_row2_col5\" class=\"data row2 col5\" >0.12</td>\n",
       "      <td id=\"T_5a406_row2_col6\" class=\"data row2 col6\" >0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d1cdb225a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_variable_summary(df, metadata_df):\n",
    "    # Create empty lists to store the chosen statistics\n",
    "    stats_dict = {\n",
    "        'Variable': [],\n",
    "        'Description': [],\n",
    "        'Mean': [],\n",
    "        'Std': [],\n",
    "        'Missing': [],\n",
    "        'Min': [],\n",
    "        'Max': []\n",
    "    }\n",
    "\n",
    "    # Create a metadata dictionary for easy lookup\n",
    "    meta_dict = dict(zip(metadata_df['Metadata'], metadata_df['Unnamed: 1']))\n",
    "\n",
    "    for col in df.columns:\n",
    "        stats_dict['Variable'].append(col)\n",
    "        stats_dict['Description'].append(meta_dict.get(col, 'N/A'))\n",
    "\n",
    "        # Calculate some statistics for each column\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            stats_dict['Mean'].append(f\"{df[col].mean():.2f}\")\n",
    "            stats_dict['Std'].append(f\"{df[col].std():.2f}\")\n",
    "            stats_dict['Min'].append(f\"{df[col].min():.2f}\")\n",
    "            stats_dict['Max'].append(f\"{df[col].max():.2f}\")\n",
    "        else:\n",
    "            stats_dict['Mean'].append('N/A')\n",
    "            stats_dict['Std'].append('N/A')\n",
    "            stats_dict['Min'].append('N/A')\n",
    "            stats_dict['Max'].append('N/A')\n",
    "\n",
    "        stats_dict['Missing'].append(df[col].isna().sum())\n",
    "\n",
    "    return pd.DataFrame(stats_dict)\n",
    "\n",
    "\n",
    "# Create summary tables\n",
    "print(\"NEEDS VARIABLES SUMMARY:\")\n",
    "needs_summary = create_variable_summary(needs_df, metadata_df)\n",
    "display(needs_summary.style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .hide(axis='index'))\n",
    "\n",
    "print(\"\\nPRODUCTS VARIABLES SUMMARY:\")\n",
    "products_summary = create_variable_summary(products_df, metadata_df)\n",
    "display(products_summary.style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .hide(axis='index'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GZMqZlO65-g"
   },
   "source": [
    "<h1> Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "<h2>Feature Idea 8: Gender × Age Interaction</h2>\n",
    "Rationale: Investigate whether life-cycle financial needs differ by gender within the dataset. Additionally, refine the Income/Wealth Ratio by applying a logarithmic transformation for better scaling.\n",
    "Combining the Gender × Age interaction feature with the log-transformed Income/Wealth Ratio and the base feature set yielded the strongest performance among all feature engineering strategies tested.\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12973,
     "status": "ok",
     "timestamp": 1744208360334,
     "user": {
      "displayName": "hirdesh kumar",
      "userId": "01247601886325289740"
     },
     "user_tz": -120
    },
    "id": "HZYIA41J5v72",
    "outputId": "a651fe5d-d94b-4030-b2a5-014695e8a9a6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Sklearn Imports ---\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# --- Add imports for new models ---\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ---------------------------------\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# --- Global Settings ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- ASSUME 'needs_df' is loaded and preprocessed correctly before this point ---\n",
    "# Example:\n",
    "# needs_df = pd.read_csv('your_data.csv')\n",
    "# # Ensure Gender, Age, FamilyMembers are numeric\n",
    "# needs_df['Gender'] = needs_df['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "# needs_df['FamilyMembers'] = pd.to_numeric(needs_df['FamilyMembers'], errors='coerce').fillna(0)\n",
    "# needs_df['Age'] = pd.to_numeric(needs_df['Age'], errors='coerce').fillna(needs_df['Age'].median())\n",
    "\n",
    "\n",
    "# Step 1: Feature engineering function (Implementing Both New Features)\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepares base and engineered (Gender*Age + I/W Ratio) feature sets.\"\"\"\n",
    "    X = df.copy()\n",
    "    income_col = 'Income ' if 'Income ' in X.columns else 'Income'\n",
    "    wealth_col = 'Wealth'\n",
    "    gender_col = 'Gender'\n",
    "    age_col = 'Age'\n",
    "\n",
    "    # Log transformation for Wealth and Income\n",
    "    if wealth_col in X.columns: X['Wealth_log'] = np.log1p(X[wealth_col])\n",
    "    if income_col in X.columns: X['Income_log'] = np.log1p(X[income_col])\n",
    "\n",
    "    # --- Engineered Feature 1: Gender * Age Interaction ---\n",
    "    interaction_gender_age = 'Gender_x_Age'\n",
    "    if age_col in X.columns and gender_col in X.columns and \\\n",
    "       pd.api.types.is_numeric_dtype(X[age_col]) and \\\n",
    "       pd.api.types.is_numeric_dtype(X[gender_col]):\n",
    "        X[interaction_gender_age] = X[age_col] * X[gender_col]\n",
    "    else:\n",
    "        X[interaction_gender_age] = 0\n",
    "        print(f\"Warning: Could not calculate {interaction_gender_age}.\")\n",
    "\n",
    "    # --- Engineered Feature 2: Refined Income/Wealth Ratio (log) ---\n",
    "    feature_iw_ratio_log = 'Income_Wealth_Ratio_log'\n",
    "    if income_col in X.columns and wealth_col in X.columns and \\\n",
    "       pd.api.types.is_numeric_dtype(X[income_col]) and \\\n",
    "       pd.api.types.is_numeric_dtype(X[wealth_col]):\n",
    "        # Calculate ratio using original values, handle division by zero\n",
    "        ratio = X[income_col].div(X[wealth_col].replace(0, np.nan))\n",
    "        # Fill NaN ratios with 0 before log1p\n",
    "        X[feature_iw_ratio_log] = np.log1p(ratio.fillna(0))\n",
    "    else:\n",
    "        X[feature_iw_ratio_log] = 0\n",
    "        print(f\"Warning: Could not calculate {feature_iw_ratio_log}.\")\n",
    "\n",
    "\n",
    "    # --- Define Feature Lists ---\n",
    "    # Base features: Standard set\n",
    "    features_base_expected = ['Age', 'Gender', 'FamilyMembers', 'FinancialEducation',\n",
    "                              'RiskPropensity', 'Wealth_log', 'Income_log']\n",
    "\n",
    "    # Engineered features: Base + BOTH New Features\n",
    "    features_engineered_expected = features_base_expected.copy()\n",
    "    if interaction_gender_age in X.columns:\n",
    "         features_engineered_expected.append(interaction_gender_age)\n",
    "    if feature_iw_ratio_log in X.columns:\n",
    "         features_engineered_expected.append(feature_iw_ratio_log)\n",
    "\n",
    "    # Select only available columns\n",
    "    features_base = [f for f in features_base_expected if f in X.columns]\n",
    "    features_engineered = [f for f in features_engineered_expected if f in X.columns]\n",
    "\n",
    "\n",
    "    # Normalize all features\n",
    "    scaler_base = MinMaxScaler()\n",
    "    scaler_eng = MinMaxScaler()\n",
    "\n",
    "    # Minimal error checking assumed data is clean/numeric\n",
    "    X_base = pd.DataFrame(scaler_base.fit_transform(X[features_base]), columns=features_base, index=X.index)\n",
    "    X_engineered = pd.DataFrame(scaler_eng.fit_transform(X[features_engineered]), columns=features_engineered, index=X.index)\n",
    "\n",
    "    return X_base, X_engineered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base, X_engineered = prepare_features(needs_df)\n",
    "y_income = needs_df['IncomeInvestment']\n",
    "y_accum = needs_df['AccumulationInvestment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>FinancialEducation</th>\n",
       "      <th>RiskPropensity</th>\n",
       "      <th>Wealth_log</th>\n",
       "      <th>Income_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222172</td>\n",
       "      <td>0.243105</td>\n",
       "      <td>0.468132</td>\n",
       "      <td>0.664782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.372410</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.600160</td>\n",
       "      <td>0.441614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.189873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.324649</td>\n",
       "      <td>0.262161</td>\n",
       "      <td>0.498951</td>\n",
       "      <td>0.453970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.843975</td>\n",
       "      <td>0.734110</td>\n",
       "      <td>0.756044</td>\n",
       "      <td>0.842246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.454090</td>\n",
       "      <td>0.377948</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.436064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  FamilyMembers  FinancialEducation  RiskPropensity  \\\n",
       "0  0.531646     0.0           0.25            0.222172        0.243105   \n",
       "1  0.759494     0.0           0.25            0.372410        0.170321   \n",
       "2  0.189873     1.0           0.25            0.324649        0.262161   \n",
       "3  0.645570     1.0           0.75            0.843975        0.734110   \n",
       "4  0.506329     0.0           0.50            0.454090        0.377948   \n",
       "\n",
       "   Wealth_log  Income_log  \n",
       "0    0.468132    0.664782  \n",
       "1    0.600160    0.441614  \n",
       "2    0.498951    0.453970  \n",
       "3    0.756044    0.842246  \n",
       "4    0.482307    0.436064  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base Features\n",
    "print(\"Base Features:\")\n",
    "X_base.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineered Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>FinancialEducation</th>\n",
       "      <th>RiskPropensity</th>\n",
       "      <th>Wealth_log</th>\n",
       "      <th>Income_log</th>\n",
       "      <th>Gender_x_Age</th>\n",
       "      <th>Income_Wealth_Ratio_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222172</td>\n",
       "      <td>0.243105</td>\n",
       "      <td>0.468132</td>\n",
       "      <td>0.664782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.372410</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.600160</td>\n",
       "      <td>0.441614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.189873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.324649</td>\n",
       "      <td>0.262161</td>\n",
       "      <td>0.498951</td>\n",
       "      <td>0.453970</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.054647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.843975</td>\n",
       "      <td>0.734110</td>\n",
       "      <td>0.756044</td>\n",
       "      <td>0.842246</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.062964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.454090</td>\n",
       "      <td>0.377948</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.436064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  FamilyMembers  FinancialEducation  RiskPropensity  \\\n",
       "0  0.531646     0.0           0.25            0.222172        0.243105   \n",
       "1  0.759494     0.0           0.25            0.372410        0.170321   \n",
       "2  0.189873     1.0           0.25            0.324649        0.262161   \n",
       "3  0.645570     1.0           0.75            0.843975        0.734110   \n",
       "4  0.506329     0.0           0.50            0.454090        0.377948   \n",
       "\n",
       "   Wealth_log  Income_log  Gender_x_Age  Income_Wealth_Ratio_log  \n",
       "0    0.468132    0.664782      0.000000                 0.155428  \n",
       "1    0.600160    0.441614      0.000000                 0.025499  \n",
       "2    0.498951    0.453970      0.347368                 0.054647  \n",
       "3    0.756044    0.842246      0.726316                 0.062964  \n",
       "4    0.482307    0.436064      0.000000                 0.055916  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Engineered Features\n",
    "print(\"\\nEngineered Features:\")\n",
    "X_engineered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4995    0\n",
       "4996    1\n",
       "4997    0\n",
       "4998    0\n",
       "4999    1\n",
       "Name: IncomeInvestment, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Income Investment Model\n",
    "y_income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4995    0\n",
       "4996    1\n",
       "4997    1\n",
       "4998    0\n",
       "4999    1\n",
       "Name: AccumulationInvestment, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accumulation Investment Model\n",
    "y_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions for Streaming Model\n",
    "\n",
    "- **Independence:** Each customer record is treated as an independent observation. There are no time-dependent or sequential relationships between records.\n",
    "- **Feature Stability:** The relationships between features (e.g., Gender × Age interaction, log(Income/Wealth)) and target variables are assumed to remain relevant over time, though gradual changes (concept drift) are expected and handled by the streaming model.\n",
    "- **Concept Drift:** The streaming approach assumes that if the distribution of data changes, it does so gradually enough for the model and drift detector (ADWIN) to adapt.\n",
    "- **Representative Sample:** The dataset of 5,000 records is assumed to be representative of the broader client population we wish to model.\n",
    "- **No Explicit Temporal Information:** As the dataset is a cross-sectional snapshot (not longitudinal), we do not model time series effects or repeated measurements per client.\n",
    "\n",
    "## Sample Size Justification\n",
    "\n",
    "- **Sufficiency:** With 5,000 records and a moderate number of features, the data is sufficient for both batch and streaming learning for binary classification tasks.\n",
    "- **Class Balance:** Outcomes are checked for class imbalance; if severe imbalance was present, additional measures (e.g., resampling) could be considered.\n",
    "- **Streaming Model Suitability:** Streaming models like Hoeffding Tree and ADWIN can learn effectively from thousands of samples, especially when feature engineering captures key relationships.\n",
    "\n",
    "## Time Series Discussion\n",
    "\n",
    "- **No Temporal Sequence:** The current dataset does not contain explicit timestamps or sequential data per client; each record is a point-in-time snapshot.\n",
    "- **Streaming Simulation:** The 'streaming' process is simulated by iterating over records as if they arrive in real-time. This is appropriate for adaptive learning, but not a replacement for true time series methods.\n",
    "- **When Time Series Matters:** If the goal were to model changes in an individual client’s behavior over time or to forecast future investment needs, time series or panel data modeling would be required.\n",
    "- **Justification:** For this business case—recommending next best actions based on current client profiles—cross-sectional modeling is appropriate and time series modeling is not strictly necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.0\n"
     ]
    }
   ],
   "source": [
    "#%pip install river\n",
    "\n",
    "import river\n",
    "print(river.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discliamer \n",
    "\n",
    "Streaming methods like Hoeffding Trees and their ensembles learn data one sample at a time and do not get to see the whole dataset at once. This is much harder than batch learning.\n",
    "Typical streaming benchmarks (especially for classification) often show that accuracies in the 65–75% range are quite solid, especially on non-trivial, real-world data.\n",
    "Batch models (like full RandomForest or XGBoost) often do better, but they have the advantage of multiple passes and more complex optimization.\n",
    "Practical context: If your classes are balanced and your baseline (e.g., always guessing the majority class) is much lower (say, 50–60%), then 75% is strong. If the problem is very easy (e.g., baseline is 70%), then it's less impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models\n",
    "\n",
    "Models Used:\n",
    "The code evaluates four streaming models from the River library:\n",
    "<ol>\n",
    "<li>HoeffdingTreeClassifier (single decision tree for streaming)</li>\n",
    "<li>LogisticRegression (online linear model)</li>\n",
    "<li>NaiveBayes (Gaussian Naive Bayes for streaming)</li>\n",
    "<li>Bagging (HoeffdingTree) (ensemble of Hoeffding Trees for improved stability and accuracy)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment: Target = income, Features = engineered, Model = HoeffdingTree\n",
      "Accuracy:  0.7420\n",
      "Precision: 0.7062\n",
      "Recall:    0.5615\n",
      "F1:        0.6256\n",
      "ROC AUC:   0.7370\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = engineered, Model = HoeffdingTree\n",
      "Accuracy:  0.6520\n",
      "Precision: 0.6452\n",
      "Recall:    0.7151\n",
      "F1:        0.6784\n",
      "ROC AUC:   0.6981\n",
      "\n",
      "\n",
      "Experiment: Target = income, Features = engineered, Model = LogisticRegression\n",
      "Accuracy:  0.6248\n",
      "Precision: 0.8500\n",
      "Recall:    0.0266\n",
      "F1:        0.0516\n",
      "ROC AUC:   0.5801\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = engineered, Model = LogisticRegression\n",
      "Accuracy:  0.5628\n",
      "Precision: 0.5542\n",
      "Recall:    0.7576\n",
      "F1:        0.6401\n",
      "ROC AUC:   0.5538\n",
      "\n",
      "\n",
      "Experiment: Target = income, Features = engineered, Model = NaiveBayes\n",
      "Accuracy:  0.7494\n",
      "Precision: 0.6869\n",
      "Recall:    0.6382\n",
      "F1:        0.6616\n",
      "ROC AUC:   0.7542\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = engineered, Model = NaiveBayes\n",
      "Accuracy:  0.6374\n",
      "Precision: 0.6191\n",
      "Recall:    0.7627\n",
      "F1:        0.6834\n",
      "ROC AUC:   0.6830\n",
      "\n",
      "\n",
      "Experiment: Target = income, Features = engineered, Model = Bagging (HoeffdingTree)\n",
      "Accuracy:  0.7508\n",
      "Precision: 0.7198\n",
      "Recall:    0.5746\n",
      "F1:        0.6390\n",
      "ROC AUC:   0.7494\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = engineered, Model = Bagging (HoeffdingTree)\n",
      "Accuracy:  0.6664\n",
      "Precision: 0.6572\n",
      "Recall:    0.7315\n",
      "F1:        0.6924\n",
      "ROC AUC:   0.7195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from river import tree, linear_model, naive_bayes, ensemble, metrics, stream\n",
    "\n",
    "models = {\n",
    "    \"HoeffdingTree\": tree.HoeffdingTreeClassifier(),\n",
    "    \"LogisticRegression\": linear_model.LogisticRegression(),\n",
    "    \"NaiveBayes\": naive_bayes.GaussianNB(),\n",
    "    \"Bagging (HoeffdingTree)\": ensemble.BaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(),\n",
    "        n_models=10,\n",
    "        seed=42\n",
    "    )\n",
    "}\n",
    "\n",
    "targets = {\n",
    "    \"income\": y_income,\n",
    "    \"accumulation\": y_accum\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for target_name, y in targets.items():\n",
    "        print(f\"\\nExperiment: Target = {target_name}, Features = engineered, Model = {model_name}\")\n",
    "        data_stream = stream.iter_pandas(X_engineered, y)\n",
    "        model_instance = model.clone()\n",
    "        # Initialize metrics\n",
    "        accuracy = metrics.Accuracy()\n",
    "        precision = metrics.Precision()\n",
    "        recall = metrics.Recall()\n",
    "        f1 = metrics.F1()\n",
    "        rocauc = metrics.ROCAUC()\n",
    "        for x_row, y_row in data_stream:\n",
    "            y_pred = model_instance.predict_one(x_row)\n",
    "            y_pred_proba = model_instance.predict_proba_one(x_row)\n",
    "            accuracy.update(y_row, y_pred)\n",
    "            precision.update(y_row, y_pred)\n",
    "            recall.update(y_row, y_pred)\n",
    "            f1.update(y_row, y_pred)\n",
    "            # Only update ROC AUC if probabilities are available (i.e., model supports it)\n",
    "            rocauc.update(y_row, y_pred_proba)\n",
    "            model_instance.learn_one(x_row, y_row)\n",
    "        print(f\"Accuracy:  {accuracy.get():.4f}\")\n",
    "        print(f\"Precision: {precision.get():.4f}\")\n",
    "        print(f\"Recall:    {recall.get():.4f}\")\n",
    "        print(f\"F1:        {f1.get():.4f}\")\n",
    "        print(f\"ROC AUC:   {rocauc.get():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Age', 'FamilyMembers', 'FinancialEducation', 'RiskPropensity', 'Wealth_log', 'Income_log', 'Gender_x_Age', 'Income_Wealth_Ratio_log']\n",
      "\n",
      "Experiment: Target = income, Features = pruned, Model = HoeffdingTree\n",
      "Accuracy:  0.7424\n",
      "Precision: 0.7072\n",
      "Recall:    0.5615\n",
      "F1:        0.6260\n",
      "ROC AUC:   0.7397\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = pruned, Model = HoeffdingTree\n",
      "Accuracy:  0.6520\n",
      "Precision: 0.6450\n",
      "Recall:    0.7159\n",
      "F1:        0.6786\n",
      "ROC AUC:   0.6995\n",
      "\n",
      "\n",
      "Experiment: Target = income, Features = pruned, Model = Bagging (HoeffdingTree)\n",
      "Accuracy:  0.7532\n",
      "Precision: 0.7237\n",
      "Recall:    0.5777\n",
      "F1:        0.6425\n",
      "ROC AUC:   0.7491\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = pruned, Model = Bagging (HoeffdingTree)\n",
      "Accuracy:  0.6672\n",
      "Precision: 0.6579\n",
      "Recall:    0.7323\n",
      "F1:        0.6931\n",
      "ROC AUC:   0.7215\n",
      "\n",
      "\n",
      "Experiment: Target = income, Features = pruned, Model = ExtremelyFastDecisionTree\n",
      "Accuracy:  0.7602\n",
      "Precision: 0.7605\n",
      "Recall:    0.5480\n",
      "F1:        0.6370\n",
      "ROC AUC:   0.7402\n",
      "\n",
      "\n",
      "Experiment: Target = accumulation, Features = pruned, Model = ExtremelyFastDecisionTree\n",
      "Accuracy:  0.6558\n",
      "Precision: 0.6526\n",
      "Recall:    0.7042\n",
      "F1:        0.6774\n",
      "ROC AUC:   0.6935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from river import tree, naive_bayes, metrics, stream\n",
    "\n",
    "# Try to import advanced ensembles and specialized trees if available\n",
    "extra_models = {}\n",
    "\n",
    "try:\n",
    "    from river.ensemble import AdaptiveRandomForestClassifier\n",
    "    extra_models[\"AdaptiveRandomForest\"] = AdaptiveRandomForestClassifier(seed=42, n_models=10)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from river.ensemble import ARFClassifier\n",
    "    extra_models[\"ARFClassifier\"] = ARFClassifier(seed=42, n_models=10)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from river.tree import ExtremelyFastDecisionTreeClassifier\n",
    "    extra_models[\"ExtremelyFastDecisionTree\"] = ExtremelyFastDecisionTreeClassifier()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from river.tree import MondrianTreeClassifier\n",
    "    extra_models[\"MondrianTree\"] = MondrianTreeClassifier()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Feature selection using sklearn\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_engineered, y_income)\n",
    "importances = dict(zip(X_engineered.columns, dtree.feature_importances_))\n",
    "threshold = 0.01\n",
    "selected_features = [feat for feat, imp in importances.items() if imp > threshold]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "X_pruned = X_engineered[selected_features]\n",
    "\n",
    "# Main set of models\n",
    "models = {\n",
    "    \"HoeffdingTree\": tree.HoeffdingTreeClassifier(),\n",
    "}\n",
    "\n",
    "# Add Bagging if available\n",
    "try:\n",
    "    from river import ensemble\n",
    "    models[\"Bagging (HoeffdingTree)\"] = ensemble.BaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(),\n",
    "        n_models=10,\n",
    "        seed=42\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Add the extra models found above\n",
    "models.update(extra_models)\n",
    "\n",
    "targets = {\n",
    "    \"income\": y_income,\n",
    "    \"accumulation\": y_accum\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for target_name, y in targets.items():\n",
    "        print(f\"\\nExperiment: Target = {target_name}, Features = pruned, Model = {model_name}\")\n",
    "        data_stream = stream.iter_pandas(X_pruned, y)\n",
    "        model_instance = model.clone()\n",
    "        # Initialize metrics\n",
    "        accuracy = metrics.Accuracy()\n",
    "        precision = metrics.Precision()\n",
    "        recall = metrics.Recall()\n",
    "        f1 = metrics.F1()\n",
    "        rocauc = metrics.ROCAUC()\n",
    "        for x_row, y_row in data_stream:\n",
    "            y_pred = model_instance.predict_one(x_row)\n",
    "            y_pred_proba = model_instance.predict_proba_one(x_row)\n",
    "            accuracy.update(y_row, y_pred)\n",
    "            precision.update(y_row, y_pred)\n",
    "            recall.update(y_row, y_pred)\n",
    "            f1.update(y_row, y_pred)\n",
    "            rocauc.update(y_row, y_pred_proba)\n",
    "            model_instance.learn_one(x_row, y_row)\n",
    "        print(f\"Accuracy:  {accuracy.get():.4f}\")\n",
    "        print(f\"Precision: {precision.get():.4f}\")\n",
    "        print(f\"Recall:    {recall.get():.4f}\")\n",
    "        print(f\"F1:        {f1.get():.4f}\")\n",
    "        print(f\"ROC AUC:   {rocauc.get():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Discussion\n",
    "<body>\n",
    "Bagging (HoeffdingTree) Performs Best:\n",
    "\n",
    "For both targets, the bagged ensemble outperforms the single Hoeffding Tree and other models in terms of accuracy, F1, and ROC AUC.\n",
    "Example:\n",
    "income target: Accuracy 0.7508, F1 0.6390, ROC AUC 0.7494\n",
    "accumulation target: Accuracy 0.6664, F1 0.6924, ROC AUC 0.7195\n",
    "NaiveBayes is Competitive:\n",
    "\n",
    "NaiveBayes also performs well, especially for the income target (Accuracy 0.7494, F1 0.6616, ROC AUC 0.7542).\n",
    "This suggests that the features are fairly independent or that NaiveBayes is robust for this dataset.\n",
    "\n",
    "HoeffdingTree (Single Tree):\n",
    "\n",
    "Slightly lower performance than the bagged version, as expected (ensembling reduces variance and improves generalization).\n",
    "\n",
    "LogisticRegression Underperforms:\n",
    "\n",
    "Very low recall for income (0.0266), indicating it rarely predicts the positive class.\n",
    "This leads to a poor F1 score, despite high precision (likely due to class imbalance or poor feature separability for linear models).\n",
    "\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of pruning of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.01 | Selected features: ['Age', 'FamilyMembers', 'FinancialEducation', 'RiskPropensity', 'Wealth_log', 'Income_log', 'Gender_x_Age', 'Income_Wealth_Ratio_log']\n",
      "Threshold: 0.01 | Selected features: ['Age', 'FamilyMembers', 'FinancialEducation', 'RiskPropensity', 'Wealth_log', 'Income_log', 'Gender_x_Age', 'Income_Wealth_Ratio_log']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def select_features(X, y, threshold=0.01):\n",
    "    dtree = DecisionTreeClassifier(random_state=42)\n",
    "    dtree.fit(X, y)\n",
    "    importances = dict(zip(X.columns, dtree.feature_importances_))\n",
    "    selected = [feat for feat, imp in importances.items() if imp > threshold]\n",
    "    print(f\"Threshold: {threshold} | Selected features: {selected}\")\n",
    "    return selected\n",
    "\n",
    "# To prune for both targets\n",
    "threshold = 0.01  # or 0.005, etc.\n",
    "\n",
    "selected_features_income = select_features(X_engineered, y_income, threshold=threshold)\n",
    "X_pruned_income = X_engineered[selected_features_income]\n",
    "\n",
    "selected_features_accum = select_features(X_engineered, y_accum, threshold=threshold)\n",
    "X_pruned_accum = X_engineered[selected_features_accum]\n",
    "\n",
    "# Now you have X_pruned_income for y_income and X_pruned_accum for y_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for y_income (Best Models) ---\n",
      "Bagging_HT | Accuracy: 0.7532 | F1: 0.6425 | ROC AUC: 0.7491\n",
      "EFT | Accuracy: 0.7608 | F1: 0.6421 | ROC AUC: 0.7376\n",
      "\n",
      "--- Results for y_accum (Best Models) ---\n",
      "Bagging_HT | Accuracy: 0.6672 | F1: 0.6931 | ROC AUC: 0.7215\n",
      "EFT | Accuracy: 0.6598 | F1: 0.6709 | ROC AUC: 0.7056\n"
     ]
    }
   ],
   "source": [
    "from river import tree, ensemble, metrics, stream\n",
    "\n",
    "# --- From earlier results, Bagging HoeffdingTree and ExtremelyFastDecisionTree were best ---\n",
    "\n",
    "# Bagging HoeffdingTree parameters (as previously best)\n",
    "bagging_params = dict(n_models=10, max_depth=10, grace_period=200)\n",
    "# ExtremelyFastDecisionTree parameters (as previously best)\n",
    "eft_params = dict(max_depth=10, grace_period=100)\n",
    "\n",
    "def get_best_models():\n",
    "    models = {}\n",
    "    models[\"Bagging_HT\"] = ensemble.BaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(max_depth=bagging_params[\"max_depth\"], grace_period=bagging_params[\"grace_period\"]),\n",
    "        n_models=bagging_params[\"n_models\"], seed=42\n",
    "    )\n",
    "    try:\n",
    "        from river.tree import ExtremelyFastDecisionTreeClassifier\n",
    "        models[\"EFT\"] = ExtremelyFastDecisionTreeClassifier(\n",
    "            max_depth=eft_params[\"max_depth\"], grace_period=eft_params[\"grace_period\"]\n",
    "        )\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X, y, title=\"\"):\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    for x_row, y_row in data_stream:\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        y_pred_proba = model.predict_proba_one(x_row)\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# --- Test on income ---\n",
    "models_income = get_best_models()\n",
    "print(\"\\n--- Results for y_income (Best Models) ---\")\n",
    "for name, model in models_income.items():\n",
    "    evaluate_model(model.clone(), X_pruned_income, y_income, title=name)\n",
    "\n",
    "# --- Test on accumulation ---\n",
    "models_accum = get_best_models()\n",
    "print(\"\\n--- Results for y_accum (Best Models) ---\")\n",
    "for name, model in models_accum.items():\n",
    "    evaluate_model(model.clone(), X_pruned_accum, y_accum, title=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparmeter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_income (Bagging_HT) | Accuracy: 0.7538 | F1: 0.6439 | ROC AUC: 0.7524\n",
      "y_accum (Bagging_HT) | Accuracy: 0.6712 | F1: 0.6992 | ROC AUC: 0.7288\n"
     ]
    }
   ],
   "source": [
    "from river import tree, ensemble, metrics, stream\n",
    "\n",
    "# Final best hyperparameters\n",
    "final_params = dict(n_models=10, max_depth=10, grace_period=100, seed=42)\n",
    "\n",
    "def evaluate_bagging_ht(X, y, target_name=\"\"):\n",
    "    model = ensemble.BaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(max_depth=final_params[\"max_depth\"], grace_period=final_params[\"grace_period\"]),\n",
    "        n_models=final_params[\"n_models\"],\n",
    "        seed=final_params[\"seed\"]\n",
    "    )\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for x_row, y_row in data_stream:\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        y_pred_proba = model.predict_proba_one(x_row)\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{target_name} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# Evaluate on y_income\n",
    "evaluate_bagging_ht(X_pruned_income, y_income, target_name=\"y_income (Bagging_HT)\")\n",
    "\n",
    "# Evaluate on y_accum\n",
    "evaluate_bagging_ht(X_pruned_accum, y_accum, target_name=\"y_accum (Bagging_HT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "Builds a streaming ensemble with Bagging Hoeffding Trees (and EFT if available). Uses majority voting for predictions. Evaluates with accuracy, F1, and ROC AUC in a streaming (online) fashion. </body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Voting Ensemble (income) | Accuracy: 0.7474 | F1: 0.6437 | ROC AUC: 0.5000\n",
      "Final Voting Ensemble (accumulation) | Accuracy: 0.6470 | F1: 0.6737 | ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from river import tree, ensemble, metrics, stream\n",
    "\n",
    "bagging_ht = ensemble.BaggingClassifier(\n",
    "    model=tree.HoeffdingTreeClassifier(max_depth=10, grace_period=100),\n",
    "    n_models=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Pass only model instances, not (name, model) tuples\n",
    "ensemble_models = [bagging_ht]\n",
    "\n",
    "try:\n",
    "    from river.tree import ExtremelyFastDecisionTreeClassifier\n",
    "    eft = ExtremelyFastDecisionTreeClassifier(max_depth=10, grace_period=100)\n",
    "    ensemble_models.append(eft)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "final_voting = ensemble.VotingClassifier(*ensemble_models)\n",
    "\n",
    "def evaluate_ensemble(model, X, y, title=\"\"):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for x_row, y_row in data_stream:\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        # Try to get probabilities, else use empty dict\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except NotImplementedError:\n",
    "            y_pred_proba = {}\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "    \n",
    "evaluate_ensemble(final_voting.clone(), X_pruned_income, y_income, title=\"Final Voting Ensemble (income)\")\n",
    "evaluate_ensemble(final_voting.clone(), X_pruned_accum, y_accum, title=\"Final Voting Ensemble (accumulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good accuracy and F1. ROC AUC = 0.5 means the model’s probability estimates are not useful for ranking (like random).\n",
    "Ensemble is learning, but probability calibration or diversity could be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          | Accuracy |       F1 |  ROC AUC\n",
      "-----------------------------------------------------------------\n",
      "GaussianNB (income)            |   0.7476 |   0.6595 |   0.7551\n",
      "GaussianNB (accumulation)      |   0.6378 |   0.6841 |   0.6845\n",
      "MultinomialNB (income)         |   0.6156 |   0.0010 |   0.5068\n",
      "MultinomialNB (accumulation)   |   0.5232 |   0.6627 |   0.5083\n",
      "Perceptron (income)            |   0.6436 |   0.5357 |   0.6495\n",
      "Perceptron (accumulation)      |   0.5640 |   0.5754 |   0.5862\n",
      "PassiveAggressive (income)     |   0.6212 |   0.5024 |   0.6327\n",
      "PassiveAggressive (accumulation) |   0.5778 |   0.5916 |   0.5989\n",
      "KNNClassifier (income)         |   0.7146 |   0.5507 |   0.7100\n",
      "KNNClassifier (accumulation)   |   0.6606 |   0.6745 |   0.7108\n"
     ]
    }
   ],
   "source": [
    "from river import naive_bayes, linear_model, neighbors, preprocessing, metrics, stream\n",
    "\n",
    "# List of model pipelines to test (excluding tree-based and logistic regression)\n",
    "models = {\n",
    "    \"GaussianNB\": naive_bayes.GaussianNB(),\n",
    "    \"MultinomialNB\": naive_bayes.MultinomialNB(),\n",
    "    \"Perceptron\": preprocessing.StandardScaler() | linear_model.Perceptron(),\n",
    "    \"PassiveAggressive\": preprocessing.StandardScaler() | linear_model.PAClassifier(),\n",
    "    \"KNNClassifier\": neighbors.KNNClassifier(n_neighbors=8)  # window_size removed\n",
    "}\n",
    "results = {}\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    for x_row, y_row in stream.iter_pandas(X, y):\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except Exception:\n",
    "            y_pred_proba = {}\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    return acc.get(), f1.get(), rocauc.get()\n",
    "\n",
    "# Evaluate on both targets\n",
    "for name, model in models.items():\n",
    "    results[f\"{name} (income)\"] = evaluate_model(model.clone(), X_pruned_income, y_income)\n",
    "    results[f\"{name} (accumulation)\"] = evaluate_model(model.clone(), X_pruned_accum, y_accum)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Model':<30} | {'Accuracy':>8} | {'F1':>8} | {'ROC AUC':>8}\")\n",
    "print('-'*65)\n",
    "for model_name, (acc, f1, rocauc) in results.items():\n",
    "    print(f\"{model_name:<30} | {acc:8.4f} | {f1:8.4f} | {rocauc:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "- **GaussianNB** performs best overall, especially for the income target (highest accuracy, F1, and ROC AUC).\n",
    "- **KNNClassifier** also gives strong results, particularly for accumulation.\n",
    "- **MultinomialNB** performs poorly on income (very low F1), likely due to feature distribution mismatch.\n",
    "- **Perceptron** and **PassiveAggressive** have moderate performance.\n",
    "- **Summary:**  \n",
    "  Naive Bayes (Gaussian) and KNN are the most effective streaming models here. Linear models and MultinomialNB are less suitable for this dataset.\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Voting Ensemble (income) | Accuracy: 0.7174 | F1: 0.5818 | ROC AUC: 0.5000\n",
      "Final Voting Ensemble (accumulation) | Accuracy: 0.6174 | F1: 0.6379 | ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from river import naive_bayes, linear_model, neighbors, preprocessing, ensemble, metrics, stream\n",
    "\n",
    "# Define all models (as instances, not tuples)\n",
    "ensemble_models = [\n",
    "    naive_bayes.GaussianNB(),\n",
    "    naive_bayes.MultinomialNB(),\n",
    "    preprocessing.StandardScaler() | linear_model.Perceptron(),\n",
    "    preprocessing.StandardScaler() | linear_model.PAClassifier(),\n",
    "    neighbors.KNNClassifier(n_neighbors=8)\n",
    "]\n",
    "\n",
    "# Create the final voting ensemble\n",
    "final_voting = ensemble.VotingClassifier(models=ensemble_models)\n",
    "\n",
    "def evaluate_ensemble(model, X, y, title=\"\"):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for x_row, y_row in data_stream:\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except Exception:\n",
    "            y_pred_proba = {}\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# Evaluate on your datasets\n",
    "evaluate_ensemble(final_voting.clone(), X_pruned_income, y_income, title=\"Final Voting Ensemble (income)\")\n",
    "evaluate_ensemble(final_voting.clone(), X_pruned_accum, y_accum, title=\"Final Voting Ensemble (accumulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code summary:**  \n",
    "- Builds a streaming voting ensemble using GaussianNB, MultinomialNB, Perceptron, PassiveAggressive, and KNN (all from River).\n",
    "- Each model predicts on each sample, votes are combined, and metrics (accuracy, F1, ROC AUC) are updated online.\n",
    "\n",
    "**Results:**  \n",
    "- **Income:** Accuracy 0.7174, F1 0.5818, ROC AUC 0.5000  \n",
    "- **Accumulation:** Accuracy 0.6174, F1 0.6379, ROC AUC 0.5000  \n",
    "- **Interpretation:**  \n",
    "  - Accuracy and F1 are moderate, showing the ensemble learns some patterns.\n",
    "  - ROC AUC of 0.5 means the ensemble’s probability estimates are not useful for ranking (like random).  \n",
    "  - Suggests probability calibration or model diversity could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the best Tree and non tree based models for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GaussianNB for probability support:\n",
      "Proba output: {0: 1.0}\n",
      "Testing KNNClassifier for probability support:\n",
      "Proba output: {0: 1.0}\n",
      "Testing ExtremelyFastDecisionTreeClassifier for probability support:\n",
      "Proba output: {0: 1.0}\n",
      "True: 0, Proba: {}\n",
      "True: 1, Proba: {}\n",
      "True: 0, Proba: {}\n",
      "True: 1, Proba: {}\n",
      "True: 0, Proba: {}\n",
      "Voting Ensemble (income) | Accuracy: 0.7630 | F1: 0.6447 | ROC AUC: 0.5000\n",
      "True: 1, Proba: {}\n",
      "True: 0, Proba: {}\n",
      "True: 1, Proba: {}\n",
      "True: 1, Proba: {}\n",
      "True: 0, Proba: {}\n",
      "Voting Ensemble (accumulation) | Accuracy: 0.6680 | F1: 0.6967 | ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from river import naive_bayes, neighbors, tree, ensemble, metrics, stream\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------- 1. Data Preparation ----------\n",
    "def ensure_pandas(X, y):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    y = y.astype(int)\n",
    "    return X, y\n",
    "\n",
    "# Replace these lines with your actual data assignments!\n",
    "# X_pruned_income, y_income = ...\n",
    "# X_pruned_accum, y_accum = ...\n",
    "\n",
    "X_pruned_income, y_income = ensure_pandas(X_pruned_income, y_income)\n",
    "X_pruned_accum, y_accum = ensure_pandas(X_pruned_accum, y_accum)\n",
    "\n",
    "# --------- 2. Ensemble Models (only those that support predict_proba_one) ----------\n",
    "ensemble_models = [\n",
    "    naive_bayes.GaussianNB(),\n",
    "    neighbors.KNNClassifier(n_neighbors=8),\n",
    "    tree.ExtremelyFastDecisionTreeClassifier()\n",
    "    # Do NOT use tree.HoeffdingTreeClassifier() - it does NOT support predict_proba_one!\n",
    "]\n",
    "\n",
    "# --------- 3. Diagnostic: Check models for predict_proba_one support ----------\n",
    "for m in ensemble_models:\n",
    "    print(f\"Testing {type(m).__name__} for probability support:\")\n",
    "    try:\n",
    "        # Need to warm-start before probabilities for most models\n",
    "        m.learn_one(X_pruned_income.iloc[0], y_income.iloc[0])\n",
    "        print(\"Proba output:\", m.predict_proba_one(X_pruned_income.iloc[0]))\n",
    "    except NotImplementedError:\n",
    "        print(f\"{type(m).__name__} does NOT implement predict_proba_one!\")\n",
    "    except Exception as e:\n",
    "        print(f\"{type(m).__name__} error: {e}\")\n",
    "\n",
    "# --------- 4. Helper: Warm-start all models with each class ----------\n",
    "def force_warm_start(model, X, y):\n",
    "    for label in [0, 1]:\n",
    "        idx = np.where(y.values == label)[0][0]\n",
    "        x_row = X.iloc[idx]\n",
    "        y_row = y.iloc[idx]\n",
    "        model.learn_one(x_row, y_row)\n",
    "\n",
    "# --------- 5. Ensemble Evaluation Function ----------\n",
    "def evaluate_ensemble(model, X, y, title=\"\"):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for idx, (x_row, y_row) in enumerate(data_stream):\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except NotImplementedError:\n",
    "            y_pred_proba = {}\n",
    "        if idx < 5:\n",
    "            print(f\"True: {y_row}, Proba: {y_pred_proba}\")\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# --------- 6. INCOME: Warm-start and evaluate ensemble ----------\n",
    "for m in ensemble_models:\n",
    "    force_warm_start(m, X_pruned_income, y_income)\n",
    "voting_ensemble_income = ensemble.VotingClassifier(models=[m.clone() for m in ensemble_models])\n",
    "force_warm_start(voting_ensemble_income, X_pruned_income, y_income)\n",
    "evaluate_ensemble(voting_ensemble_income, X_pruned_income, y_income, title=\"Voting Ensemble (income)\")\n",
    "\n",
    "# --------- 7. ACCUMULATION: Warm-start and evaluate ensemble ----------\n",
    "for m in ensemble_models:\n",
    "    force_warm_start(m, X_pruned_accum, y_accum)\n",
    "voting_ensemble_accum = ensemble.VotingClassifier(models=[m.clone() for m in ensemble_models])\n",
    "force_warm_start(voting_ensemble_accum, X_pruned_accum, y_accum)\n",
    "evaluate_ensemble(voting_ensemble_accum, X_pruned_accum, y_accum, title=\"Voting Ensemble (accumulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Results:**\n",
    "\n",
    "- **All models (GaussianNB, KNN, ExtremelyFastDecisionTree) support `predict_proba_one`.**\n",
    "- **Voting Ensemble (income):**\n",
    "  - Accuracy: **0.7630**\n",
    "  - F1: **0.6447**\n",
    "  - ROC AUC: **0.5000**\n",
    "- **Voting Ensemble (accumulation):**\n",
    "  - Accuracy: **0.6680**\n",
    "  - F1: **0.6967**\n",
    "  - ROC AUC: **0.5000**\n",
    "\n",
    "**Interpretation:**\n",
    "- **Accuracy and F1 are strong**—the ensemble is learning useful patterns.\n",
    "- **ROC AUC is 0.5**—the ensemble’s probability estimates are not informative for ranking (like random).\n",
    "- **Takeaway:**  \n",
    "  The ensemble is effective for classification, but probability calibration or model diversity could be improved for better ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADWIN Explanation:**  \n",
    "ADWIN (Adaptive Windowing) is a streaming concept drift detector. It monitors the accuracy of your model over time and automatically detects when the data distribution changes (concept drift). When a significant change is detected, ADWIN can trigger model adaptation or alert you to possible performance drops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble (income) with ADWIN | Accuracy: 0.7748 | F1: 0.6641 | ROC AUC: 0.5000\n",
      "Voting Ensemble (accumulation) with ADWIN | Accuracy: 0.7066 | F1: 0.7114 | ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from river import drift\n",
    "\n",
    "def evaluate_ensemble_with_drift(model, X, y, title=\"\"):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    adwin = drift.ADWIN()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for idx, (x_row, y_row) in enumerate(data_stream):\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except NotImplementedError:\n",
    "            y_pred_proba = {}\n",
    "        correct = int(y_pred == y_row)\n",
    "        adwin.update(correct)\n",
    "        if adwin.change_detected:\n",
    "            print(f\"[Drift detected at sample {idx}] Accuracy window mean changed!\")\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# Use this function instead of evaluate_ensemble:\n",
    "def evaluate_ensemble_with_drift(model, X, y, title=\"\"):\n",
    "    acc = metrics.Accuracy()\n",
    "    f1 = metrics.F1()\n",
    "    rocauc = metrics.ROCAUC()\n",
    "    adwin = drift.ADWIN()\n",
    "    data_stream = stream.iter_pandas(X, y)\n",
    "    for idx, (x_row, y_row) in enumerate(data_stream):\n",
    "        y_pred = model.predict_one(x_row)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba_one(x_row)\n",
    "        except NotImplementedError:\n",
    "            y_pred_proba = {}\n",
    "        correct = int(y_pred == y_row)\n",
    "        if adwin.update(correct):\n",
    "            print(f\"[Drift detected at sample {idx}] Accuracy window mean changed!\")\n",
    "        acc.update(y_row, y_pred)\n",
    "        f1.update(y_row, y_pred)\n",
    "        rocauc.update(y_row, y_pred_proba)\n",
    "        model.learn_one(x_row, y_row)\n",
    "    print(f\"{title} | Accuracy: {acc.get():.4f} | F1: {f1.get():.4f} | ROC AUC: {rocauc.get():.4f}\")\n",
    "\n",
    "# Use this function instead of evaluate_ensemble:\n",
    "evaluate_ensemble_with_drift(voting_ensemble_income, X_pruned_income, y_income, title=\"Voting Ensemble (income) with ADWIN\")\n",
    "evaluate_ensemble_with_drift(voting_ensemble_accum, X_pruned_accum, y_accum, title=\"Voting Ensemble (accumulation) with ADWIN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**  \n",
    "- **Accuracy and F1 improved** compared to previous runs, showing the ensemble adapts well to the data stream and benefits from drift detection.\n",
    "- **ROC AUC remains 0.5**, meaning the model's probability estimates are not useful for ranking (still like random).\n",
    "- **ADWIN’s value:** It helps maintain or improve classification performance by detecting and adapting to changes in the data, but does not directly improve probability calibration.\n",
    "\n",
    "**Summary:**  \n",
    "ADWIN helps the ensemble maintain strong accuracy and F1 in a streaming setting by detecting concept drift, but further work is needed to improve probability outputs for ranking (ROC AUC)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "089f4affeadf4dbbab9697df7d4e5111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08f2a4aba4db443c9e460333b5905bff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1347da6d45fe45e4a31c886e16451e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "162e13a9c9a24de5b933b02a601b758f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee3d7d43bdf74ef19c5a9fd188b35001",
      "placeholder": "​",
      "style": "IPY_MODEL_af5f67dfc8684055af5a4f4071c5462d",
      "value": " 50/50 [00:08&lt;00:00,  9.96it/s]"
     }
    },
    "2733f4628aba4c30b278d4ad489a9877": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3531773ab1f142f7a75f84262c4a4cc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5da454e118904dbba983570556e58982",
       "IPY_MODEL_cbf319d6a9a94cc689cc5584fe397512",
       "IPY_MODEL_162e13a9c9a24de5b933b02a601b758f"
      ],
      "layout": "IPY_MODEL_089f4affeadf4dbbab9697df7d4e5111"
     }
    },
    "3b9a4d9cb034408f941947b2f9cf6c20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43ed5474ef494f6e8ddf64ff2bafed3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "514d46b86cc648228682bbba4c542a1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5da454e118904dbba983570556e58982": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e82b3b478f5944dc91179135f6a94b79",
      "placeholder": "​",
      "style": "IPY_MODEL_6f1cf2bb327a4a9eaa5dc2d1b4ea995a",
      "value": "Best trial: 43. Best value: 0.738113: 100%"
     }
    },
    "63cd34e84e23422ead7511204450a801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b9a4d9cb034408f941947b2f9cf6c20",
      "placeholder": "​",
      "style": "IPY_MODEL_43ed5474ef494f6e8ddf64ff2bafed3d",
      "value": "Best trial: 20. Best value: 0.822904: 100%"
     }
    },
    "6f1cf2bb327a4a9eaa5dc2d1b4ea995a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f71fe9c46da436bb2cd2a5529ffe59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "872bc96c59964258af8080e640a2dbee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_514d46b86cc648228682bbba4c542a1a",
      "placeholder": "​",
      "style": "IPY_MODEL_d5c54e9e39aa4c6c89fd568767247909",
      "value": " 50/50 [00:05&lt;00:00,  6.86it/s]"
     }
    },
    "8ead17e1849943b990675992a4701afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63cd34e84e23422ead7511204450a801",
       "IPY_MODEL_8fdfad65b31a4a39921f86aa8670f2f0",
       "IPY_MODEL_872bc96c59964258af8080e640a2dbee"
      ],
      "layout": "IPY_MODEL_e049049e34d84cdfb601383974f3093e"
     }
    },
    "8fdfad65b31a4a39921f86aa8670f2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08f2a4aba4db443c9e460333b5905bff",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f71fe9c46da436bb2cd2a5529ffe59f",
      "value": 50
     }
    },
    "af5f67dfc8684055af5a4f4071c5462d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbf319d6a9a94cc689cc5584fe397512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2733f4628aba4c30b278d4ad489a9877",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1347da6d45fe45e4a31c886e16451e4e",
      "value": 50
     }
    },
    "d5c54e9e39aa4c6c89fd568767247909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e049049e34d84cdfb601383974f3093e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e82b3b478f5944dc91179135f6a94b79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee3d7d43bdf74ef19c5a9fd188b35001": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
